--> to check the upgrade plan run
# kubeadm upgrade plan

(if you are running more than 3 recent version from latest version then it will not show all stable release beacuse it can support upto 3 backwards releases)

(so you need to specify the version number, like below)

# root@k8master:~# kubeadm upgrade plan v1.31.0
[preflight] Running pre-flight checks.
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[upgrade] Running cluster health checks
[upgrade] Fetching available versions to upgrade to
[upgrade/versions] Cluster version: 1.30.14
[upgrade/versions] kubeadm version: v1.30.14
[upgrade/versions] Target version: v1.31.0
[upgrade/versions] Latest version in the v1.30 series: v1.31.0

Components that must be upgraded manually after you have upgraded the control plane with 'kubeadm upgrade apply':
COMPONENT   NODE       CURRENT    TARGET
kubelet     k8master   v1.30.14   v1.31.0
kubelet     k8node1    v1.30.14   v1.31.0

Upgrade to the latest version in the v1.30 series:

COMPONENT                 NODE       CURRENT    TARGET
kube-apiserver            k8master   v1.30.14   v1.31.0
kube-controller-manager   k8master   v1.30.14   v1.31.0
kube-scheduler            k8master   v1.30.14   v1.31.0
kube-proxy                           1.30.14    v1.31.0
CoreDNS                              v1.11.3    v1.11.3
etcd                      k8master   3.5.15-0   3.5.15-0

You can now apply the upgrade by executing the following command:

        kubeadm upgrade apply v1.31.0

Note: Before you can perform this upgrade, you have to update kubeadm to v1.31.0.

_____________________________________________________________________


The table below shows the current state of component configs as understood by this version of kubeadm.
Configs that have a "yes" mark in the "MANUAL UPGRADE REQUIRED" column require manual config upgrade or
resetting to kubeadm defaults before a successful upgrade can be performed. The version to manually
upgrade to is denoted in the "PREFERRED VERSION" column.

API GROUP                 CURRENT VERSION   PREFERRED VERSION   MANUAL UPGRADE REQUIRED
kubeproxy.config.k8s.io   v1alpha1          v1alpha1            no
kubelet.config.k8s.io     v1beta1           v1beta1             no
_____________________________________________________________________



--> above command will list the current version and target version and what all componanats needs to upgrade manually.

--> we might need to upgade the kubeadm first to support the next version of kuberenetes

--> check the current version of kubeadm and kubelet as below:
# root@k8master:~# apt-cache policy kubeadm
kubeadm:
  Installed: 1.30.14-1.1
  Candidate: 1.34.0-ubuntu24.04u2
 (which might show the lastest but if you need to install the next version then check the list and specify the version as below)

 #  apt-get upgrade kubeadm=1.30.14-1.1

 and might need or a good idea to hold the version of kubeadm to currently upgraded version so that, it will not get upgraded by mistake since it suppoort upto 3 recent version. So , its a good idea until we have cluster done, put the hold to version as below:

 # apt-mark hold kubeadm

 # apt-mark showhold (to list the holded package)

 # apt-mark unhold <package_name> (to unhold the package)

 ####################################
 ####################################

        CLUSTER UPGRADE

#####################################
#####################################

step1) check the kubeadm, kubectl and kubelet version (kubeadm version must be ahead of one version from current version)
    - check the current version
    # root@k8master:~/CKA# kubectl get nodes
      NAME       STATUS   ROLES           AGE   VERSION
      k8master   Ready    control-plane   38m   v1.30.14
      k8node1    Ready    <none>          23m   v1.30.14

    # root@k8master:~/CKA/labs# kubeadm version
      kubeadm version: &version.Info{Major:"1", Minor:"30", GitVersion:"v1.30.14", GitCommit:"9e18483918821121abdf9aa82bc14d66df5d68cd", GitTreeState:"clean", BuildDate:"2025-06-17T18:34:53Z", GoVersion:"go1.23.10", Compiler:"gc", Platform:"linux/amd64"}
    
    # root@k8master:~/CKA/labs# kubelet --version
      Kubernetes v1.30.14 

    # root@k8master:~/CKA/labs# kubectl version
      Client Version: v1.30.14
      Kustomize Version: v5.7.1
      Server Version: v1.30.14

    (here we can see kubeadm is at same version where server is running, so we need to update the kubeadm first)

step2) upgrade the kubeadm
    - update the source/repo list
    # echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
    # apt-get update

    - upgrade the kubeadm now
    # apt-get upgrade kubeadm=1.31.13-1.1

    - now, run the plan and apply it:
    # kubeadm upgrade plan v1.31.0      (will show the next target version of each componants)
    # kubeadm upgrade apply v1.31.0     (will uprgade the cluster to target version)

    [upgrade/successful] SUCCESS! Your cluster was upgraded to "v1.31.13". Enjoy!

    [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven't already done so.

step3) check the current version:
    # root@k8master:~/CKA# kubectl get nodes
      NAME       STATUS   ROLES           AGE   VERSION
      k8master   Ready    control-plane   38m   v1.30.14
      k8node1    Ready    <none>          23m   v1.30.14

    (still showing the old version, we need to upgrade the kubelet to load the new server configuration)

    # apt-get upgrade -y kubelet=1.31.13-1.1  (make sure, you will put the same version as we did for kubeadm)

    # systemctl restart kubelet

    # root@k8master:~/CKA# kubectl get nodes            (now after restart of kubelet on master node, we can see latest version for master but not worker node)
      NAME       STATUS   ROLES           AGE   VERSION
      k8master   Ready    control-plane   39m   v1.31.13
      k8node1    Ready    <none>          23m   v1.30.14

step4) now, we need to update the kubeadm and kubelet on worker node
    - If we are running multiple worker nodes and any pods are running on worker node which we are upgrading then, it would be nice to cordon the node
    - OR if running a test workload or ok to get the downtime for those app (since node might need reboot if you are upgrading OS), then you can do without cordon also.

    - OPTIONAL Steps (to be performed on master node)
    # kubectl drain <node_name> (in this case, workload will be evicted to another available node if meets all requirements)
        OR
    # kubectl cordon <node_name> (in this case, workload needs to be moved/evicted manually)

    - update the source/repo list
    # echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.31/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list
    # apt-get update

    # apt-get upgrade kubeadm=1.31.13-1.1 (make sure, you will put the same version as we did for kubeadm on master node)
    # apt-get upgrade kubelet=1.31.13-1.1 (make sure, you will put the same version as we did for kubeadm on master node)
    
    -now upgrade the kubelet configuration:
    # kubeadm upgrade node  

step5) verify the version now on all nodes, run on master node
    # root@k8master:~/CKA# kubectl get nodes
      NAME       STATUS   ROLES           AGE   VERSION
      k8master   Ready    control-plane   44m   v1.31.13
      k8node1    Ready    <none>          29m   v1.31.13

step6) IF NODES WAS CORDENED OR DRAINED
    # kubectl uncordon <node_name>

IF you have other worker nodes, then repeat the steps from step4 to step6.
